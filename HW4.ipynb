{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sW17EniM6Dy_",
        "D0UNxYrQ4t5c",
        "4W3qo2Tk6JKa",
        "9ztwhgfG6QVA",
        "5tMICT3X6U8a",
        "d89sQ93K-9NO",
        "5RvBAelP47Cb",
        "X-OwzSzP_MsM",
        "l7TDACm9-cyg",
        "28ie7D1--ige",
        "gs5f9Qsz-mlL",
        "YyI5pY8SAPfF",
        "_zvkAWxFASqf",
        "w9wNYuXWAVww",
        "2rZC7bPD-pD_",
        "MRVbv8D8_Qsw",
        "2vZYruCi-2t5",
        "KrQnxJTrAoLV",
        "uTaaBK-VAr_f",
        "4HMQOu00Awd0",
        "xfJjCm-sAyIu",
        "6R57lwYFA1F3",
        "40_cfqRLA75l",
        "AKx-jcpu49zi",
        "Hw38LwY_6i__",
        "EtJlHBIxHIud",
        "AIQrguh4GU9Y",
        "bbnr7SMpGXsv",
        "Coes7Yk_BC43",
        "GiKj31_VJgQi",
        "2mO0yIh1JvOw",
        "5BgMCKaYJ1ER",
        "4leu-QG_BFBE",
        "in5Z-TM_6mH7",
        "RsWtpbG85C-E",
        "QyipgZgA6r5p",
        "37RTAXNg6uNu",
        "AJ1O8gvfBqR8",
        "qQXs6lLpBxph",
        "1GgvuagtB0x9",
        "lUs9f3oH5GMU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trevinofernando/AI-MachineLearning/blob/master/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW17EniM6Dy_",
        "colab_type": "text"
      },
      "source": [
        "#Machine Learning topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0UNxYrQ4t5c",
        "colab_type": "text"
      },
      "source": [
        "##Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W3qo2Tk6JKa",
        "colab_type": "text"
      },
      "source": [
        "###Artificial Inteligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sAoSkSJ7hbv",
        "colab_type": "text"
      },
      "source": [
        "Is any device that mimics functions that humans associate with the human mind, such as \"learning\" and \"problem solving\" or machines that perceives its environment and takes actions that maximize its chance of successfully achieving its goals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ztwhgfG6QVA",
        "colab_type": "text"
      },
      "source": [
        "###Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MndJNkx-9j0P",
        "colab_type": "text"
      },
      "source": [
        "Is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. The goal is to understand the structure of the data – fit theoretical distributions to the data that are well understood. So, with statistical models there is a theory behind the model that is mathematically proven, but this requires that data meets certain strong assumptions too. Machine learning has developed based on the ability to use computers to probe the data for structure, even if we do not have a theory of what that structure looks like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tMICT3X6U8a",
        "colab_type": "text"
      },
      "source": [
        "###Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2R80UoT92ut",
        "colab_type": "text"
      },
      "source": [
        "Deep learning combines advances in computing power and special types of neural networks to learn complicated patterns in large amounts of data.Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89sQ93K-9NO",
        "colab_type": "text"
      },
      "source": [
        "###Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyc2UUtCCgm4",
        "colab_type": "text"
      },
      "source": [
        "Is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RvBAelP47Cb",
        "colab_type": "text"
      },
      "source": [
        "##Building a model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-OwzSzP_MsM",
        "colab_type": "text"
      },
      "source": [
        "###Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7TDACm9-cyg",
        "colab_type": "text"
      },
      "source": [
        "####Convolutional Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ie7D1--ige",
        "colab_type": "text"
      },
      "source": [
        "#####Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs5f9Qsz-mlL",
        "colab_type": "text"
      },
      "source": [
        "######Conv2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GKAX9_YCttk",
        "colab_type": "text"
      },
      "source": [
        "Keras Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyI5pY8SAPfF",
        "colab_type": "text"
      },
      "source": [
        "######Strides"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq4q41YcC_az",
        "colab_type": "text"
      },
      "source": [
        "It specifies what is the distance between consecutive applications of convolutional filters. The value of 1 in a specific dimension means that we apply the operator at every row/col, the value of 2 means every second, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zvkAWxFASqf",
        "colab_type": "text"
      },
      "source": [
        "######Kernel Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU55wc-cDJgW",
        "colab_type": "text"
      },
      "source": [
        "Is the size of a convolutional filter, and likewise a \"kernel\" is the filter itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9wNYuXWAVww",
        "colab_type": "text"
      },
      "source": [
        "######Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLAPRHnLDU0B",
        "colab_type": "text"
      },
      "source": [
        "It allows us to design deeper networks. Without padding, reduction in volume size would reduce too quickly. Padding actually improves performance by keeping information at the borders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rZC7bPD-pD_",
        "colab_type": "text"
      },
      "source": [
        "#####MaxPooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf01uljpDg7V",
        "colab_type": "text"
      },
      "source": [
        "Is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRVbv8D8_Qsw",
        "colab_type": "text"
      },
      "source": [
        "####Dense Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gka7mxjDtr8",
        "colab_type": "text"
      },
      "source": [
        "A Dense layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer. It's the most basic layer in neural networks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vZYruCi-2t5",
        "colab_type": "text"
      },
      "source": [
        "####Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK-Kyl2uAlGY",
        "colab_type": "text"
      },
      "source": [
        "Is often used in neural networks, to map the non-normalized output of a network to a probability distribution over predicted output classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrQnxJTrAoLV",
        "colab_type": "text"
      },
      "source": [
        "###Activation Funtion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTaaBK-VAr_f",
        "colab_type": "text"
      },
      "source": [
        "####Sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQvKN0eSEasR",
        "colab_type": "text"
      },
      "source": [
        "f(x) = 1 / (1 + e^(-x))\n",
        "\n",
        "In general, a sigmoid function is monotonic, and has a first derivative which is bell shaped. A sigmoid function is constrained by a pair of horizontal asymptotes as x approaches positive or negative infinity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HMQOu00Awd0",
        "colab_type": "text"
      },
      "source": [
        "####RELU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsWb52G4FOqQ",
        "colab_type": "text"
      },
      "source": [
        "The Rectified Linear Unit: f(x) = max(0, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfJjCm-sAyIu",
        "colab_type": "text"
      },
      "source": [
        "####LeakyRELU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVOFNQpFibW",
        "colab_type": "text"
      },
      "source": [
        "f(x) = max(0.01x, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R57lwYFA1F3",
        "colab_type": "text"
      },
      "source": [
        "####Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEeLv-CSECFY",
        "colab_type": "text"
      },
      "source": [
        "Is often used in neural networks, to map the non-normalized output of a network to a probability distribution over predicted output classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40_cfqRLA75l",
        "colab_type": "text"
      },
      "source": [
        "####tanh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw4EGufZFv5_",
        "colab_type": "text"
      },
      "source": [
        "f(x) = tanh(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKx-jcpu49zi",
        "colab_type": "text"
      },
      "source": [
        "##Compiling a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw38LwY_6i__",
        "colab_type": "text"
      },
      "source": [
        "###Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtJlHBIxHIud",
        "colab_type": "text"
      },
      "source": [
        "####Adagrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf_0ZHsuHOBf",
        "colab_type": "text"
      },
      "source": [
        "Adapts learning rate for each parameter separately. In many gradient descent methods is one learning rate for all trainable variables(features), now Adagrad allows to consider every parameter.\n",
        "\n",
        "**Drawbacks**:\n",
        "\n",
        "During training we accumulate gradients that leads to a large number in the denominator, hence learning rate becomes too small and training is stoping.\n",
        "\n",
        "**Applications**:\n",
        "\n",
        "It suits for sparse data, GloVe used this optimizer for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIQrguh4GU9Y",
        "colab_type": "text"
      },
      "source": [
        "####RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiSnm2iIGfkX",
        "colab_type": "text"
      },
      "source": [
        "The main goal of RMSProp (Root Mean Square Propagation) is to fix the drawback of Adagrad. Hinton uses the exponential moving averages instead of sum of the squared gradients\n",
        "\n",
        "**Drawbacks**:\n",
        "\n",
        "There are no so obvious drawbacks, just that learning rate is still handcrafted,because not for every task the suggested value is appropriate.\n",
        "\n",
        "**Applications**:\n",
        "\n",
        "Good for training CNNs, deep networks. MobileNets was trained with RMSProp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbnr7SMpGXsv",
        "colab_type": "text"
      },
      "source": [
        "####ADAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppN-MEmgIMdR",
        "colab_type": "text"
      },
      "source": [
        "Adam (Adaptive Moment Estimation) works with momentums of first and second order. The intuition behind the Adam is that we don’t want to roll so fast just because we can jump over the minimum, we want to decrease the velocity a little bit for careful search.\n",
        "\n",
        "**Applications**\n",
        "\n",
        "Very good for deep CNNs.\n",
        "\n",
        "**Drawbacks**\n",
        "\n",
        "Learning rate is handcrafted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Coes7Yk_BC43",
        "colab_type": "text"
      },
      "source": [
        "###Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-tXGeK_JUdG",
        "colab_type": "text"
      },
      "source": [
        "Typically, with neural networks, we seek to minimize the error. As such, the objective function is often referred to as a cost function or a loss function and the value calculated by the loss function is referred to as simply “loss.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiKj31_VJgQi",
        "colab_type": "text"
      },
      "source": [
        "####Regression Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-xsDPumJj8c",
        "colab_type": "text"
      },
      "source": [
        "A problem where you predict a real-value quantity.\n",
        "\n",
        "* **Output Layer Configuration:** One node with a linear activation unit.\n",
        "* **Loss Function:** Mean Squared Error (MSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mO0yIh1JvOw",
        "colab_type": "text"
      },
      "source": [
        "####Binary Classification Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns1WnA0yJ4AJ",
        "colab_type": "text"
      },
      "source": [
        "A problem where you classify an example as belonging to one of two classes.\n",
        "\n",
        "The problem is framed as predicting the likelihood of an example belonging to class one, e.g. the class that you assign the integer value 1, whereas the other class is assigned the value 0.\n",
        "\n",
        "* **Output Layer Configuration:** One node with a sigmoid activation unit.\n",
        "* **Loss Function:** Cross-Entropy, also referred to as Logarithmic loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BgMCKaYJ1ER",
        "colab_type": "text"
      },
      "source": [
        "####Multi-Class Classification Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwjhDcbKKCP-",
        "colab_type": "text"
      },
      "source": [
        "A problem where you classify an example as belonging to one of more than two classes.\n",
        "\n",
        "The problem is framed as predicting the likelihood of an example belonging to each class.\n",
        "\n",
        "* **Output Layer Configuration:** One node for each class using the softmax activation function.\n",
        "* **Loss Function:** Cross-Entropy, also referred to as Logarithmic loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4leu-QG_BFBE",
        "colab_type": "text"
      },
      "source": [
        "###Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zkvZBDfKQmg",
        "colab_type": "text"
      },
      "source": [
        "A metric is a function that is used to judge the performance of your model. A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in5Z-TM_6mH7",
        "colab_type": "text"
      },
      "source": [
        "###Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3geaKkHKiTW",
        "colab_type": "text"
      },
      "source": [
        "Is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWtpbG85C-E",
        "colab_type": "text"
      },
      "source": [
        "##Training a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyipgZgA6r5p",
        "colab_type": "text"
      },
      "source": [
        "###Overfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_QDdw0dL4Nc",
        "colab_type": "text"
      },
      "source": [
        "Is a modeling error that occurs when a function is too closely fit to a limited set of data points. Overfitting the model generally takes the form of making an overly complex model to explain idiosyncrasies in the data under study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37RTAXNg6uNu",
        "colab_type": "text"
      },
      "source": [
        "###Underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umXfOgspMDha",
        "colab_type": "text"
      },
      "source": [
        "Occurs when a model is too simple — informed by too few features or regularized too much — which makes it inflexible in learning from the dataset. Simple learners tend to have less variance in their predictions but more bias towards wrong outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ1O8gvfBqR8",
        "colab_type": "text"
      },
      "source": [
        "##Figthing Overfiting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQXs6lLpBxph",
        "colab_type": "text"
      },
      "source": [
        "###Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN6wMyWgMTcX",
        "colab_type": "text"
      },
      "source": [
        "Is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GgvuagtB0x9",
        "colab_type": "text"
      },
      "source": [
        "###Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjBMejzYMh9M",
        "colab_type": "text"
      },
      "source": [
        "Is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. ... The term \"dropout\" refers to dropping out units (both hidden and visible) in a neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUs9f3oH5GMU",
        "colab_type": "text"
      },
      "source": [
        "###Finetuning  a Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xZ20cpPM1V6",
        "colab_type": "text"
      },
      "source": [
        "Is a process to take a network model that has already been trained for a given task, and make it perform a second similar task"
      ]
    }
  ]
}